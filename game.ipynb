{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyboy import PyBoy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "print(\"Python:\", sys.executable)\n",
    "\n",
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "print(\"Gymnasium:\", gym.__version__)\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "print(\"SB3 imported OK\")\n",
    "\n",
    "# --- quick CartPole sanity test (optional, can comment out later) ---\n",
    "env_test = gym.make(\"CartPole-v1\")\n",
    "obs, info = env_test.reset()\n",
    "print(\"CartPole obs:\", obs)\n",
    "\n",
    "model_test = PPO(\"MlpPolicy\", env_test, n_steps=64, batch_size=32, verbose=0)\n",
    "model_test.learn(total_timesteps=100)\n",
    "print(\"PPO sanity test passed.\")\n",
    "env_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- constants from before ---\n",
    "MAP_ID_ADDR   = 0xD35E\n",
    "PLAYER_Y_ADDR = 0xD361\n",
    "PLAYER_X_ADDR = 0xD362\n",
    "\n",
    "# Keep your 8-button action space for now\n",
    "ACTIONS = {\n",
    "    0: lambda pb: None,\n",
    "    1: lambda pb: pb.button(\"up\"),\n",
    "    2: lambda pb: pb.button(\"down\"),\n",
    "    3: lambda pb: pb.button(\"left\"),\n",
    "    4: lambda pb: pb.button(\"right\"),\n",
    "    5: lambda pb: pb.button(\"a\"),\n",
    "    6: lambda pb: pb.button(\"b\"),\n",
    "    7: lambda pb: pb.button(\"start\"),\n",
    "}\n",
    "NUM_ACTIONS = len(ACTIONS)\n",
    "\n",
    "\n",
    "class PokemonRedEnv:\n",
    "    \"\"\"\n",
    "    Task:\n",
    "      - Start inside the first house.\n",
    "      - Leave the house (map id changes).\n",
    "\n",
    "    Rewards:\n",
    "      - step penalty:              -0.001\n",
    "      - move to a different tile:  +0.01\n",
    "      - visit a new tile:          +0.02\n",
    "      - leave starting map:        +1.0  (episode done)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rom_path: str, state_path: str, max_steps: int = 300):\n",
    "        self.rom_path = rom_path\n",
    "        self.state_path = state_path\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        self.pyboy = None\n",
    "        self.game = None\n",
    "\n",
    "        self.initial_map_id = None      # map where the episode starts\n",
    "        self.current_floor_map_id = None\n",
    "        self.has_exited_initial = False\n",
    "\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.prev_player_pos = None  # (x, y)\n",
    "        self.visited = set()         # {(map_id, x, y)}\n",
    "\n",
    "    # ---- helpers ----\n",
    "\n",
    "    def _init_emulator(self):\n",
    "        self.pyboy = PyBoy(\n",
    "            self.rom_path,\n",
    "            window=\"null\",    # headless for training\n",
    "            no_input=False,   # IMPORTANT: allow input from ACTIONS\n",
    "        )\n",
    "        self.game = self.pyboy.game_wrapper\n",
    "\n",
    "    def _get_map_id(self) -> int:\n",
    "        return int(self.pyboy.memory[MAP_ID_ADDR])\n",
    "\n",
    "    def _get_player_pos(self) -> tuple[int, int]:\n",
    "        y = int(self.pyboy.memory[PLAYER_Y_ADDR])\n",
    "        x = int(self.pyboy.memory[PLAYER_X_ADDR])\n",
    "        return (x, y)  # (x, y) consistently\n",
    "\n",
    "    def _get_obs(self) -> np.ndarray:\n",
    "        return np.array(self.game.game_area(), dtype=np.int16)\n",
    "\n",
    "    # ---- API ----\n",
    "\n",
    "    def reset(self):\n",
    "        # stop any previous emu\n",
    "        if self.pyboy is not None:\n",
    "            self.pyboy.stop()\n",
    "\n",
    "        self._init_emulator()\n",
    "\n",
    "        # load your starting save state\n",
    "        with open(self.state_path, \"rb\") as f:\n",
    "            self.pyboy.load_state(f)\n",
    "\n",
    "        # settle a bit\n",
    "        for _ in range(10):\n",
    "            self.pyboy.tick()\n",
    "\n",
    "        self.initial_map_id = self._get_map_id()\n",
    "        self.current_floor_map_id = self.initial_map_id\n",
    "        self.has_exited_initial = False\n",
    "        self.step_count = 0\n",
    "\n",
    "        pos = self._get_player_pos()\n",
    "        self.prev_player_pos = pos\n",
    "        self.visited = {(self.current_floor_map_id, *pos)}\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        return obs\n",
    "\n",
    "    def step(self, action: int):\n",
    "        self.step_count += 1\n",
    "\n",
    "        # ---- apply action ----\n",
    "        ACTIONS[int(action)](self.pyboy)\n",
    "\n",
    "        for _ in range(3):\n",
    "            self.pyboy.tick()\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        current_map = self._get_map_id()\n",
    "        pos = self._get_player_pos()\n",
    "        old_pos = self.prev_player_pos\n",
    "\n",
    "        done = False\n",
    "        reward = -0.01  # step penalty\n",
    "\n",
    "        moved = (pos != old_pos)\n",
    "        if moved:\n",
    "            reward += 0.5\n",
    "            key = (current_map, *pos)\n",
    "            if key not in self.visited:\n",
    "                reward += 5\n",
    "                self.visited.add(key)\n",
    "\n",
    "        self.prev_player_pos = pos\n",
    "\n",
    "        # â¬‡ï¸ exiting the initial room: give bonus, but DO NOT end episode\n",
    "        if (not self.has_exited_initial) and (current_map != self.initial_map_id):\n",
    "            reward += 20.0\n",
    "            self.has_exited_initial = True\n",
    "\n",
    "            # optional: treat new map as new \"floor\" for exploration\n",
    "            self.current_floor_map_id = current_map\n",
    "            self.visited = {(current_map, *pos)}\n",
    "\n",
    "        # global episode limit\n",
    "        if self.step_count >= self.max_steps:\n",
    "            done = True\n",
    "\n",
    "        info = {\"map_id\": current_map, \"player_pos\": pos}\n",
    "\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def close(self):\n",
    "        if self.pyboy is not None:\n",
    "            self.pyboy.stop()\n",
    "            self.pyboy = None\n",
    "            self.game = None\n",
    "\n",
    "class VisualPokemonRedEnv(PokemonRedEnv):\n",
    "    def _init_emulator(self):\n",
    "        self.pyboy = PyBoy(\n",
    "            self.rom_path,\n",
    "            window=\"SDL2\",   # GUI window\n",
    "            no_input=False,  # ðŸ‘ˆ still allow input from .button()\n",
    "        )\n",
    "        self.game = self.pyboy.game_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2841cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== GYM WRAPPER (Gymnasium-compatible) ======\n",
    "\n",
    "class PokemonRedGymWrapper(gym.Env):\n",
    "    \"\"\"\n",
    "    Gymnasium-compatible wrapper around PokemonRedEnv.\n",
    "    This is what you pass to Stable-Baselines3.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": []}\n",
    "\n",
    "    def __init__(self, rom_path, state_path, max_steps: int = 500):\n",
    "        super().__init__()\n",
    "        self.env = PokemonRedEnv(rom_path, state_path, max_steps=max_steps)\n",
    "\n",
    "        # Observation: 18x20 integer grid\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=300,     # safe upper bound for tile IDs\n",
    "            shape=(18, 20),\n",
    "            dtype=np.int16,\n",
    "        )\n",
    "\n",
    "        # Actions: 8 discrete actions\n",
    "        self.action_space = spaces.Discrete(NUM_ACTIONS)\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        # Gymnasium reset signature: returns (obs, info)\n",
    "        if seed is not None:\n",
    "            # we don't use seed internally yet, but gymnasium expects the arg\n",
    "            np.random.seed(seed)\n",
    "        obs = self.env.reset()\n",
    "        info = {}\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        action = int(action)\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        terminated = done\n",
    "        truncated = False\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "        super().close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87072056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== PPO TRAINING ON POKÃ‰MON ======\n",
    "\n",
    "gym_env = PokemonRedGymWrapper(\"red.gb\", \"pokemon_red_start.state\", max_steps=1000)\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    gym_env,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-4,\n",
    "    n_steps=512,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=100_000)\n",
    "print(\"PPO training on PokÃ©mon completed.\")\n",
    "\n",
    "gym_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02862b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(model, env, n_episodes=20, max_steps=1000):\n",
    "    successes = 0\n",
    "    rewards = []\n",
    "\n",
    "    for ep in range(n_episodes):\n",
    "        obs, info = env.reset()\n",
    "        start_map = env.env.initial_map_id\n",
    "        total_reward = 0.0\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            action, _ = model.predict(obs, deterministic=False)\n",
    "            action = int(action)\n",
    "\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            done = terminated or truncated\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        final_map = info[\"map_id\"]\n",
    "        success = (final_map != start_map)\n",
    "        if success:\n",
    "            successes += 1\n",
    "\n",
    "        rewards.append(total_reward)\n",
    "        print(\n",
    "            f\"Episode {ep}: reward={total_reward:.3f}, \"\n",
    "            f\"start_map={start_map}, final_map={final_map}, success={success}, \"\n",
    "            f\"final_pos={info.get('player_pos')}\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\nSuccesses: {successes}/{n_episodes}\")\n",
    "    print(f\"Average reward: {np.mean(rewards):.3f}\")\n",
    "\n",
    "evaluate_agent(model, gym_env, n_episodes=20, max_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_env = VisualPokemonRedEnv(\"red.gb\", \"pokemon_red_start.state\", max_steps=1000)\n",
    "\n",
    "obs = vis_env.reset()\n",
    "start_map_id = vis_env.initial_map_id\n",
    "total_reward = 0.0\n",
    "\n",
    "for t in range(300):\n",
    "    action, _ = model.predict(obs, deterministic=False)\n",
    "    action = int(action)\n",
    "\n",
    "    obs, reward, done, info = vis_env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "\n",
    "vis_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
